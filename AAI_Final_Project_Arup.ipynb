{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a5zzzvobsdwH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGjB4fy1uTgP",
        "outputId": "2a50a5f7-44c7-4038-c61c-51fbbe59d423"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogen\n",
            "  Downloading autogen-0.9.6-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ag2==0.9.6 (from autogen)\n",
            "  Downloading ag2-0.9.6-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (4.9.0)\n",
            "Collecting asyncer==0.0.8 (from ag2==0.9.6->autogen)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting diskcache (from ag2==0.9.6->autogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from ag2==0.9.6->autogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=2.6.1 in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (2.11.7)\n",
            "Collecting python-dotenv (from ag2==0.9.6->autogen)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (3.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ag2==0.9.6->autogen) (0.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.6->autogen) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.6->autogen) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=3.0.0->ag2==0.9.6->autogen) (4.14.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.6->autogen) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.28.1->ag2==0.9.6->autogen) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.28.1->ag2==0.9.6->autogen) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.6->autogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.6->autogen) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6.1->ag2==0.9.6->autogen) (0.4.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.6->autogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->ag2==0.9.6->autogen) (2.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ag2==0.9.6->autogen) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->ag2==0.9.6->autogen) (3.4.2)\n",
            "Downloading autogen-0.9.6-py3-none-any.whl (13 kB)\n",
            "Downloading ag2-0.9.6-py3-none-any.whl (859 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m859.2/859.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, diskcache, docker, asyncer, ag2, autogen\n",
            "Successfully installed ag2-0.9.6 asyncer-0.0.8 autogen-0.9.6 diskcache-5.6.3 docker-7.1.0 python-dotenv-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnW0NCeQujTB",
        "outputId": "6e83163f-9469-4678-a1d2-231f7b1ca62f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.5.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.68)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.72-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.5.2-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.72-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.5.2 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.72 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Core Components: The Tool Functions"
      ],
      "metadata": {
        "id": "bLZVlWS0r5DK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8qhP_ETImKqy"
      },
      "outputs": [],
      "source": [
        "# @title Tool Functions\n",
        "# These functions simulate calling deployed ML models.\n",
        "\n",
        "def fetch_movie_data(title: str) -> dict:\n",
        "    \"\"\"\n",
        "    Fetches movie data from a live source like the TMDb API[cite: 6].\n",
        "    \"\"\"\n",
        "    print(f\"TOOL: Fetching data for '{title}'...\")\n",
        "    # Dummy data for demonstration\n",
        "    return {\n",
        "        \"title\": title,\n",
        "        \"budget\": 160000000, # [cite: 2]\n",
        "        \"plot_overview\": \"A thief who steals corporate secrets through use of dream-sharing technology...\", # [cite: 2]\n",
        "    }\n",
        "\n",
        "def predict_revenue(movie_data: dict) -> float:\n",
        "    \"\"\"Calls the deployed regression model to predict box office revenue.\"\"\"\n",
        "    print(\"TOOL: Predicting revenue...\")\n",
        "    return 829895144.0\n",
        "\n",
        "def classify_success(movie_data: dict) -> dict:\n",
        "    \"\"\"Calls the deployed classification model to predict success.\"\"\"\n",
        "    print(\"TOOL: Classifying success...\")\n",
        "    return {\"class\": \"High Success\", \"confidence\": 0.92}\n",
        "\n",
        "def identify_genres_from_plot(plot_overview: str) -> list:\n",
        "    \"\"\"Calls the deployed NLP model to identify genres from a plot summary.\"\"\"\n",
        "    print(\"TOOL: Identifying genres from plot...\")\n",
        "    return [\"Action\", \"Science Fiction\", \"Thriller\"]\n",
        "\n",
        "def get_recommendations(plot_overview: str, genres: list) -> list:\n",
        "    \"\"\"Uses content-based filtering to find similar movies.\"\"\"\n",
        "    print(\"TOOL: Generating recommendations...\")\n",
        "    return [\n",
        "        {\"title\": \"The Matrix\", \"imdb_id\": \"tt0133093\"},\n",
        "        {\"title\": \"Shutter Island\", \"imdb_id\": \"tt1130884\"},\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation with LangGraph"
      ],
      "metadata": {
        "id": "4WpYZ_T6sHoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Define the Graph State"
      ],
      "metadata": {
        "id": "avW4aBCAsayz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define LangGraph State and Nodes\n",
        "from typing import TypedDict, List, Dict\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Define the state object that will be passed between nodes\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"Represents the state of our graph.\"\"\"\n",
        "    movie_title: str\n",
        "    movie_data: Dict\n",
        "    predicted_revenue: float\n",
        "    success_metrics: Dict\n",
        "    identified_genres: List[str]\n",
        "    recommendations: List[Dict]\n",
        "    final_result: Dict\n"
      ],
      "metadata": {
        "id": "PPbKUaRrsL_c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Create Graph Nodes"
      ],
      "metadata": {
        "id": "a5zzzvobsdwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the nodes of the graph\n",
        "def data_fetcher_node(state: GraphState) -> GraphState:\n",
        "    title = state[\"movie_title\"]\n",
        "    movie_data = fetch_movie_data(title)\n",
        "    return {\"movie_data\": movie_data}\n",
        "\n",
        "def revenue_node(state: GraphState) -> GraphState:\n",
        "    revenue = predict_revenue(state[\"movie_data\"])\n",
        "    return {\"predicted_revenue\": revenue}\n",
        "\n",
        "def success_node(state: GraphState) -> GraphState:\n",
        "    success = classify_success(state[\"movie_data\"])\n",
        "    return {\"success_metrics\": success}\n",
        "\n",
        "def genre_node(state: GraphState) -> GraphState:\n",
        "    genres = identify_genres_from_plot(state[\"movie_data\"][\"plot_overview\"])\n",
        "    return {\"identified_genres\": genres}\n",
        "\n",
        "def recommendation_node(state: GraphState) -> GraphState:\n",
        "    recs = get_recommendations(\n",
        "        state[\"movie_data\"][\"plot_overview\"],\n",
        "        state[\"identified_genres\"]\n",
        "    )\n",
        "    return {\"recommendations\": recs}\n",
        "\n",
        "def compile_result_node(state: GraphState) -> GraphState:\n",
        "    result = {\n",
        "        \"movie_title\": state[\"movie_title\"],\n",
        "        \"analysis\": {\n",
        "            \"predicted_revenue\": state[\"predicted_revenue\"],\n",
        "            \"success_prediction\": state[\"success_metrics\"],\n",
        "            \"identified_genres\": state[\"identified_genres\"],\n",
        "            \"recommendations\": state[\"recommendations\"]\n",
        "        }\n",
        "    }\n",
        "    print(\"\\n--- FINAL RESULT COMPILED ---\")\n",
        "    return {\"final_result\": result}"
      ],
      "metadata": {
        "id": "Gm5QS3yvscj2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Wire the Graph"
      ],
      "metadata": {
        "id": "Q9XzzWvJssJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Wire and Run the LangGraph Workflow\n",
        "import json\n",
        "\n",
        "# Initialize the stateful graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"fetch_data\", data_fetcher_node)\n",
        "workflow.add_node(\"predict_revenue\", revenue_node)\n",
        "workflow.add_node(\"classify_success\", success_node)\n",
        "workflow.add_node(\"identify_genres\", genre_node)\n",
        "workflow.add_node(\"get_recommendations\", recommendation_node)\n",
        "workflow.add_node(\"compile_results\", compile_result_node)\n",
        "\n",
        "# Define the workflow edges\n",
        "workflow.set_entry_point(\"fetch_data\")\n",
        "workflow.add_edge(\"fetch_data\", \"predict_revenue\")\n",
        "workflow.add_edge(\"fetch_data\", \"classify_success\")\n",
        "workflow.add_edge(\"fetch_data\", \"identify_genres\")\n",
        "workflow.add_edge([\"predict_revenue\", \"classify_success\", \"identify_genres\"], \"get_recommendations\")\n",
        "workflow.add_edge(\"get_recommendations\", \"compile_results\")\n",
        "workflow.add_edge(\"compile_results\", END)\n",
        "\n",
        "# Compile and run the graph\n",
        "app = workflow.compile()\n",
        "inputs = {\"movie_title\": \"Inception\"}\n",
        "result = app.invoke(inputs)\n",
        "\n",
        "print(json.dumps(result['final_result'], indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cSyAT4wstk8",
        "outputId": "2f9ee036-8fd3-4c36-b910-da074d9684e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOOL: Fetching data for 'Inception'...\n",
            "TOOL: Identifying genres from plot...\n",
            "TOOL: Classifying success...\n",
            "TOOL: Predicting revenue...\n",
            "TOOL: Generating recommendations...\n",
            "\n",
            "--- FINAL RESULT COMPILED ---\n",
            "{\n",
            "  \"movie_title\": \"Inception\",\n",
            "  \"analysis\": {\n",
            "    \"predicted_revenue\": 829895144.0,\n",
            "    \"success_prediction\": {\n",
            "      \"class\": \"High Success\",\n",
            "      \"confidence\": 0.92\n",
            "    },\n",
            "    \"identified_genres\": [\n",
            "      \"Action\",\n",
            "      \"Science Fiction\",\n",
            "      \"Thriller\"\n",
            "    ],\n",
            "    \"recommendations\": [\n",
            "      {\n",
            "        \"title\": \"The Matrix\",\n",
            "        \"imdb_id\": \"tt0133093\"\n",
            "      },\n",
            "      {\n",
            "        \"title\": \"Shutter Island\",\n",
            "        \"imdb_id\": \"tt1130884\"\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}