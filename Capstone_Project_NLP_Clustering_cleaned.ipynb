{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1EUvYATENkG"
   },
   "source": [
    "# NLP Section - Movies recommendation system (Capstone project)\n",
    "\n",
    "### Responsible team member: Rene Ortiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "d-kT3olFGprd"
   },
   "outputs": [],
   "source": [
    "#!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpzq-uoVF5P2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#EDA Profiling library\n",
    "#from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 19166,
     "status": "ok",
     "timestamp": 1752366330950,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "nYXUhGrFGpoe",
    "outputId": "04e6e7a5-1911-4a4e-f46c-5948e3d99e8b"
   },
   "outputs": [],
   "source": [
    "# load movie dataset from Google Drive using pandas\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load CSV file\n",
    "df = pd.read_csv('/content/drive/MyDrive/Capstone_Project/movies.csv')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752175498671,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "3s4S6eGYychj",
    "outputId": "e4fe77a0-24aa-49ea-8dba-c012ba9a2c3c"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5U7MKAGNypXW"
   },
   "outputs": [],
   "source": [
    "# I created this function after the initial trainings as I realized a json string is not a good strategy, JSON needs to be parse for better results\n",
    "import ast\n",
    "\n",
    "# clean function for genre and keyword fields\n",
    "def extract_names(json_str):\n",
    "    try:\n",
    "        items = ast.literal_eval(json_str)\n",
    "        return \" \".join([item['name'] for item in items if 'name' in item])\n",
    "    except (ValueError, SyntaxError):\n",
    "        return \"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cf03939e86264a178fe8919978fd5b29",
      "07f085c4eec341d683d0efc9722e77b0",
      "7f6fa21a8e08444d8cf92517c45496fd",
      "11b2dcbe7a5c4e958df3288016afcd8b",
      "070833487f9f48e2acf9edaf353d483b",
      "82d25b8f421d4019b1fefe36bd90b92f",
      "b988460b583345c6a5a21ba72780206b",
      "a7c6a44fbf804de89f1563f18dae2316",
      "7d32a1dfd58045d18a3cb1416d92963b",
      "2255850a18794a73a3287603cd8e54c3",
      "7e973025b9a34a63b4604a541a7b2576",
      "dbaf079bc687485ca7e2dab131fcf771",
      "48fd68070fc94b7ca541442848e228ef",
      "c66b974680a64d08b67c7202c9ec6eea",
      "fe37bfd2d0374903a9447eccfa0e4c65",
      "47688cffafdc4198a347428624abf73e",
      "bb83e92a7a7147a7910bf45d3be58203",
      "9b948e190e334d56bb73b3cd738fcd64",
      "173e60d62d4d4d528f23ba1f4cbaf234",
      "690027a00b9a4502b95674781a476a22",
      "ef6b5cb88a86456e9b3f7ed6d5f2fc4e",
      "600be5ada9d546fabf1789ab600f4372",
      "e9c7ae5a8d53407f830e48e9dc51115f",
      "f06ac163e31646279e57e89271c7dbca",
      "55ff13c73f81456a8e90c467676cf9ec",
      "80002bd91ab64fd090bac5c753d2fcbd",
      "83795a8303914850967a89df97886db3",
      "ec0fc6d84df34c42aab938c262b69cd9",
      "10561433262543dc9d69f4a60caf5e56",
      "2d75ab47c2a64d6d960bded865c81127",
      "beff4790bac24fef8f3753fd07a50ad8",
      "b19cc51384b340c78cbdf8435fafd489",
      "7fcb5ac9d6704a7a92f09f376d7b47d4"
     ]
    },
    "executionInfo": {
     "elapsed": 24021,
     "status": "ok",
     "timestamp": 1752004224538,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "Xw_gS2fsGpuc",
    "outputId": "560039a0-25ba-4c49-8759-66397105333c"
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJmtcXj6q4kP"
   },
   "source": [
    "## *Recommendation Models Section :  TF-IDF , BERT and LSTM*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrU1-13pSOzN"
   },
   "source": [
    "# TERM Frequency-Inverse Document Frequency Recommendation system using the following logic:\n",
    "\n",
    "- Combining features like genres, keywords, and overview text into a single string for each movie.\n",
    "\n",
    "- Converting text into vectors using this techniques: TF-IDF (Term Frequency-Inverse Document Frequency) and CountVectorizer.\n",
    "\n",
    "- Calculating similarity between movies using cosine similarity.\n",
    "\n",
    "- Returning the top-N most similar movies for a given input movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752091798392,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "0ddjptBFQaXR",
    "outputId": "defa1831-f608-46cf-f28a-c68e06be5ce2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1752091800856,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "gQTOdVYYQaba",
    "outputId": "36901ae5-91f4-460c-ec93-791049832adb"
   },
   "outputs": [],
   "source": [
    "df_clean = df[['title', 'overview', 'genres', 'keywords', 'popularity', 'release_date']].dropna()\n",
    "\n",
    "# format JSON strings from genre and keyboards\n",
    "df_clean['genres'] = df_clean['genres'].apply(extract_names)\n",
    "df_clean['keywords'] = df_clean['keywords'].apply(extract_names)\n",
    "\n",
    "# Get the from each\n",
    "df_text = df_clean[['title', 'overview', 'genres', 'keywords']]\n",
    "df_text.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1752091806285,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "cNtID6cRQafE",
    "outputId": "609a0857-151a-4951-8386-bc0560162068"
   },
   "outputs": [],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1752091816473,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "psxwlcJkQail",
    "outputId": "1f9bf23c-f5f6-46ea-9580-cc2794ab8f51"
   },
   "outputs": [],
   "source": [
    "# Combine text into a single feature\n",
    "def combine_features(row):\n",
    "    return f\"{row['overview']} {row['genres']} {row['keywords']}\"\n",
    "\n",
    "df_text['combined_text'] = df_text.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1752091818625,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "qdDzvP0qQal1",
    "outputId": "9277d91d-9d7a-420f-9593-23036bf6aec2"
   },
   "outputs": [],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752091822340,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "b3uCAsZ6Qaok",
    "outputId": "f81a4a34-7e45-4c38-cd69-a315b3677d54"
   },
   "outputs": [],
   "source": [
    "df_text['combined_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2480,
     "status": "ok",
     "timestamp": 1752091831803,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "QMXnDmTvQart",
    "outputId": "e24a2d72-30eb-4d7e-c89e-8988c9ba399a"
   },
   "outputs": [],
   "source": [
    "# Remove stop words and Word Cloud for 5 movies (reference purposes only)\n",
    "def clean_text(text):\n",
    "    tokens = text.lower().split()\n",
    "    return \" \".join([word for word in tokens if word not in stop_words and word.isalpha()])\n",
    "\n",
    "df_text['clean_text'] = df_text['combined_text'].apply(clean_text)\n",
    "\n",
    "# Generate word cloud for first 5 movies\n",
    "for i in range(5):\n",
    "    wc = WordCloud(width=600, height=400, background_color='white').generate(df_text['clean_text'].iloc[i])\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(df['title'].iloc[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rsQTKZidrYD"
   },
   "source": [
    "# Clean text to vectors using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFlm1b7aQavZ"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df_text['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752091838386,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "RPM-DR_PeDXS",
    "outputId": "73ebe0ce-4cca-4073-e12f-2cf2035fab3c"
   },
   "outputs": [],
   "source": [
    "tfidf_matrix.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1752091840180,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "ObL20JHtYwOE",
    "outputId": "5df3a0ac-8843-4fba-8f43-b01c6b6d200e"
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIAEBNJWWFJM"
   },
   "outputs": [],
   "source": [
    "df_clean['release_date'] = pd.to_datetime(df_clean['release_date'], errors='coerce').dt.year\n",
    "df_clean['release_year'] = df_clean['release_date'].fillna(0).astype(int)\n",
    "df_clean['popularity'] = pd.to_numeric(df_clean['popularity'], errors='coerce').fillna(0)\n",
    "# metadata: release year and popularity\n",
    "metadata = df_clean[['release_year', 'popularity']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752091848511,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "0uwYxwl7uWuM",
    "outputId": "a7e6c60d-ffe9-4a08-8bcc-0f3f7793bb25"
   },
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YTXCXNglWLWa"
   },
   "outputs": [],
   "source": [
    "# normalize the metadata\n",
    "scaler = MinMaxScaler()\n",
    "normalized_metadata = scaler.fit_transform(metadata[['release_year', 'popularity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Yn4LhNRWREF"
   },
   "outputs": [],
   "source": [
    "# combine TF-IDF vectors with metadata (This steps needs a GPU otherwise it takes significant time)\n",
    "tfidf_dense = tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXyPrQO7WeLQ"
   },
   "outputs": [],
   "source": [
    "# stack features\n",
    "hybrid_features_tfidf = np.hstack([tfidf_dense, normalized_metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTTbLCVyQayb"
   },
   "outputs": [],
   "source": [
    "# Compute Cosine Similarity\n",
    "#cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim = cosine_similarity(hybrid_features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752091861654,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "wnym4AaeQa2h",
    "outputId": "714edef7-0126-4dce-85b5-47fc486dde90"
   },
   "outputs": [],
   "source": [
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4Dk66mbgCeB"
   },
   "outputs": [],
   "source": [
    "# compute similarity matrix for the hybrid TF-IDF + metadata model\n",
    "similarity_matrix = cosine_similarity(hybrid_features_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xuNsB56y3aK"
   },
   "source": [
    "# Functions to call recommendations, sim-scores, genre the TMDB API (queryposters and cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGcyHa3JhERl"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# API key\n",
    "api_key = \"b400409e22d456acb002b98fa90b2c2d\" # I got this key by registering on TMDB website\n",
    "\n",
    "# get poster URL from TMDb\n",
    "def get_poster_url(movie_title):\n",
    "    try:\n",
    "        url = f\"https://api.themoviedb.org/3/search/movie?api_key={api_key}&query={movie_title}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if data[\"results\"] and data[\"results\"][0].get(\"poster_path\"):\n",
    "            poster_path = data[\"results\"][0][\"poster_path\"]\n",
    "            return f\"https://image.tmdb.org/t/p/w300{poster_path}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching poster for {movie_title}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GbZUCno05uZ"
   },
   "outputs": [],
   "source": [
    "# Recommendation function with poster display\n",
    "def recommend_movies(title, top_n=5):\n",
    "    idx = df_clean[df_clean['title'].str.lower() == title.lower()].index\n",
    "    if len(idx) == 0:\n",
    "        print(\"Movie not found.\")\n",
    "        return\n",
    "\n",
    "    idx = idx[0]\n",
    "    sim_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    recommendations = df_clean[['title', 'genres', 'keywords', 'overview']].iloc[movie_indices].copy()\n",
    "    recommendations['similarity_score'] = [sim[1] for sim in sim_scores]\n",
    "\n",
    "    # Display posters and details\n",
    "    for _, row in recommendations.iterrows():\n",
    "        title = row['title']\n",
    "        poster_url = get_poster_url(title)\n",
    "        print(f\"\\n {title} (Similarity Score: {row['similarity_score']:.3f})\")\n",
    "        print(f\"Genres: {row['genres']}\")\n",
    "        print(f\"Keywords: {row['keywords']}\")\n",
    "        if poster_url:\n",
    "            display(Image(url=poster_url))\n",
    "        else:\n",
    "            print(\"Poster not found.\")\n",
    "\n",
    "    return recommendations.sort_values(by='similarity_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTYpP1UPhEJH"
   },
   "outputs": [],
   "source": [
    "def explain_recommendation(input_title, recommended_df):\n",
    "    input_row = df_clean[df_clean['title'].str.lower() == input_title.lower()].iloc[0]\n",
    "    input_genres = set(input_row['genres'].split(','))\n",
    "    input_keywords = set(input_row['keywords'].split(','))\n",
    "\n",
    "    explanations = []\n",
    "\n",
    "    for _, row in recommended_df.iterrows():\n",
    "        rec_genres = set(row['genres'].split(','))\n",
    "        rec_keywords = set(row['keywords'].split(','))\n",
    "        common_genres = input_genres.intersection(rec_genres)\n",
    "        common_keywords = input_keywords.intersection(rec_keywords)\n",
    "\n",
    "        explanation = {\n",
    "            'title': row['title'],\n",
    "            'similarity_score': row['similarity_score'],\n",
    "            'shared_genres': ', '.join(common_genres),\n",
    "            'shared_keywords': ', '.join(common_keywords)\n",
    "        }\n",
    "        explanations.append(explanation)\n",
    "\n",
    "    return pd.DataFrame(explanations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3774,
     "status": "ok",
     "timestamp": 1752091878750,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "FdsK4toKhEOY",
    "outputId": "ffb04224-1b91-484c-a0c9-795992c7a5e1"
   },
   "outputs": [],
   "source": [
    "recs = recommend_movies(\"Superman\", top_n=5)\n",
    "explanations = explain_recommendation(\"Superman\", recs)\n",
    "display(explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clGo46JDfKD8"
   },
   "source": [
    "# Movie Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyI7ZOpdGp3c"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSa9RFsOeQq_"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(df_text['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5vu21FmeQud"
   },
   "outputs": [],
   "source": [
    "num_clusters = 5  # We can try less or more depending how we want to present this on the project\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df_text['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eP3PBd6BeQxH"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=42)\n",
    "reduced = pca.fit_transform(X.toarray())\n",
    "\n",
    "df_text['pca1'] = reduced[:, 0]\n",
    "df_text['pca2'] = reduced[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1752091929859,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "QPmYj8yoeQ0s",
    "outputId": "3ab1c4d8-b4fe-4bff-ebcb-24b9b1fb2e59"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x=\"pca1\", y=\"pca2\", hue=\"cluster\", palette=\"tab10\", data=df_text, s=60, alpha=0.7\n",
    ")\n",
    "# For refence, I'm adding labels for some sample movies\n",
    "sample_titles = df_text.groupby('cluster').apply(lambda x: x.sample(1, random_state=42))\n",
    "for _, row in sample_titles.iterrows():\n",
    "    plt.text(row['pca1'], row['pca2'], row['title'], fontsize=9)\n",
    "plt.title(\"Movie Clusters Based on Content (TF-IDF + KMeans + PCA)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752091938348,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "89X1Lav2gVGy",
    "outputId": "983f2667-91c2-4b20-e81c-cf1350f5ce37"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Re-use your TF-IDF vectorizer\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(\"\\nTop terms per cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    for j in range(10):\n",
    "        print(f\"  {terms[order_centroids[i, j]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 29126,
     "status": "ok",
     "timestamp": 1752091981545,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "-2eIIyGtiCMl",
    "outputId": "600d17b6-c969-4b69-8d7c-6648c9b8b809"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=300, random_state=42)\n",
    "X_embedded = tsne.fit_transform(X.toarray())\n",
    "\n",
    "df_text['tsne1'], df_text['tsne2'] = X_embedded[:,0], X_embedded[:,1]\n",
    "\n",
    "# Plot with t-SNE\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='tsne1', y='tsne2', hue='cluster', data=df_text, palette='tab10', alpha=0.7)\n",
    "plt.title(\"Movie Clusters Based on Content (TF-IDF + KMeans + t-SNE)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UeIDq4ukajW"
   },
   "source": [
    "# Hybrid Approach - BERT\n",
    "\n",
    "This next section will combine multiple text and numeric features:\n",
    "\n",
    "- Textual features (overview, keywords)\n",
    "\n",
    "- Metadata (genre, release year, cast)\n",
    "\n",
    "- Ratings / popularity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYgb73AwiCP6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 96,
     "status": "ok",
     "timestamp": 1752092317624,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "GGvonFzXszeW",
    "outputId": "a4837a05-6580-42b0-e942-d7d464afa07e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXhp_jX50pxH"
   },
   "outputs": [],
   "source": [
    "df_clean = df[['title', 'overview', 'genres', 'keywords', 'popularity', 'release_date']].dropna()\n",
    "\n",
    "# format JSON strings from genre and keyboards\n",
    "df_clean['genres'] = df_clean['genres'].apply(extract_names)\n",
    "df_clean['keywords'] = df_clean['keywords'].apply(extract_names)\n",
    "\n",
    "# Get the from each\n",
    "df_text = df_clean[['title', 'overview', 'genres', 'keywords']]\n",
    "df_text.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1752092717139,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "5ntUhSyS0p7e",
    "outputId": "18cd38eb-687a-44af-ada9-b0c23e7d64f9"
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4UBKfN6ktjo"
   },
   "outputs": [],
   "source": [
    "# text fields for BERT input\n",
    "df_clean['combined_text'] = df['overview'] + \" \" + df['genres'] + \" \" + df['keywords']\n",
    "\n",
    "# release date to year\n",
    "#df_clean['release_date'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year.fillna(0).astype(int)\n",
    "df_clean['release_date'] = pd.to_datetime(df_clean['release_date'], errors='coerce').dt.year\n",
    "df_clean['release_year'] = df_clean['release_date'].fillna(0).astype(int)\n",
    "df_clean['popularity'] = pd.to_numeric(df_clean['popularity'], errors='coerce').fillna(0)\n",
    "# metadata: release year and popularity\n",
    "metadata = df_clean[['release_year', 'popularity']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "2a327f35d7d9434287d6e936ba4dae3f",
      "d0ce9064f5a743aa83a7f9e35c3113a9",
      "156f50029c8a4e69a32ac413252b81f8",
      "fd39c1f30afd41c6b7af88e468e3e32c",
      "77579e0b686c4fcdbf8ede64620f86b7",
      "7a72145081db452b88781d42c567a4eb",
      "bd653994818042278b33248f0096b69c",
      "ee5530ba72c849b7a22f6a1d319bd3ad",
      "937a1679402a42bc84cd2933f34c2f1f",
      "913be98aeb0f475889414172e4149aeb",
      "0aa6db5748c5419cbfd4a2c4bf403e89",
      "ba122c5e2ded4e7dbf7f6c53fd0e7700",
      "231bd755720a477697c23e58dddc91f5",
      "feb5d9742a8749e18cac1ef06897d153",
      "01eefeda927a4f1e937e87ff2fab345d",
      "9069bbcd76ff42f7bec1e5f3476835a9",
      "6ed1b81a477a4d9993cb71bb180a888a",
      "7506e3b279084b85a2f8c3ae2ce316bd",
      "70760796783a4e6b90bc433e9c51cbdd",
      "569ddec6251c4fef86a31eb541affcc5",
      "21f5e2897bf24169a6b16e6e71682d64",
      "43e20ddfe3d44cfdb0dcb961419bbf0e",
      "1a7a766d43c94a78a4fd7b6c035a4403",
      "47e8fc7e73e647aab00edb6536566a71",
      "859be3ab54cf42c7a25fb13e2d99ef3c",
      "7ece3ca817034da7b251582e7f4d2c96",
      "2a3d2c92d5454c53b25b38e862728ed9",
      "c5dbd67e413145369fa471265192d070",
      "684cea60d86f4612827e9db55176d710",
      "cff3f14ccdfa4228b37a93427347fc6b",
      "7c4fd2c58dad4058a3b93b6ee31e4b2b",
      "c1b125412b7b46e592d6e1d1425f127e",
      "7cfa4e0237414fd591993de90cd511ed",
      "72ed40ec3f2346debd4b8717ff63b79d",
      "a45525666e504c7db1e75710b01bbe39",
      "5a11db4bf2c54ef5896f8eb2e028b8c1",
      "d98f3c7276b443d0a4554213e51d233a",
      "9a5a846927834ea697fc8c7a8e93e866",
      "f4e6d21a6ebf4591afc88c9fe1f7b2be",
      "cca64ab3cf4342b88118a84a29acc588",
      "ff19855c270b4f3ca34bde8d94de1360",
      "ecf4ba4072b9416ca5a5355ed4d15760",
      "85e5c9f5d08649c7b72fc0f4eb25defc",
      "a2494cb4f5874724bb737679083cf6bf",
      "47462b522fc041f4bb975748f6f28cc3",
      "1afc33b64e76434d9858b1532dd08fa2",
      "99ffdfa9c6b84f89ac211d8d2b35a7ee",
      "ba3b658a163d4605b0ed7eb31552c02e",
      "f1267d7be0e64b5886cc4d56c9c4f582",
      "a8f429593e284906835c8e0168e2e90d",
      "716edaa0361749deb182c63afda9a059",
      "081bd0e47d9949119fe80f5b9b263672",
      "5a75987ee57d4a35a46548870de62c0c",
      "4c1c3e99ed064acdb6ad957bb51b90f3",
      "364113c1a088469b8fd9253b221c0397",
      "fb4f9a246d7345f0b464c61716ab4d52",
      "bd44b8d62909472789fec0209553e2f6",
      "826eef8715cc475d88fe9b6352ea8084",
      "ffe21e8afd0a49648b0952826e854f5c",
      "598b5fdea3c344dab35bf7e8a15bdcaa",
      "632acc23880842a6a4d79e49c20d2be0",
      "23601ed6dbbd43ecb72314aae60d997f",
      "12f1d3280e3b473185934a27ad3e77b6",
      "b63f8f4cca0145a3b5f234b0b5ef6ce1",
      "b6df083c81b848d98524f4d5e6d79328",
      "d4e0e072b94549b595bc33b9a831e3b2",
      "9e3bc758440f46638ef64dd8be1566bf",
      "e8369fefd1a742608523e00eb82957db",
      "ab4eb91dce93460ba2f6cc44d761f38f",
      "a02749161a6141f397bd1914a3eb4839",
      "1ae21f787d0046b98c9ed80a2463af6c",
      "8021dc56d2234fdcb5fa860e03f12679",
      "24f8e5a223bc492c9b2408cf5c085525",
      "57a00d6ef5644f0a84d9f814f7936d27",
      "04e1c751efa24fe4868e321c0e1fc7a4",
      "7a918c7660544fecb3bcd76495f12f7e",
      "f3f65a4c182b4e17955f2a73d53fe92e",
      "0abc1705ab81438d8f14a4bf17cbb57f",
      "be076c5ce0ec43ae9f4a8e09a59daa38",
      "e1fddcaf16f94fc5a031aac44246d652",
      "80c30f282aa444b4b202640cf885b3f7",
      "e23b61ee2727423f95ad33dc95e12a03",
      "dd5f56573a254431a25ea1cb5f1e79b1",
      "8651d74a14a743de8694d37b47413db1",
      "2b43b054ae0b4d259cf7bf68691b77ea",
      "f763b902af074bc3b194e2ee798c9a18",
      "2669ccd32302443982ded101f22aab62",
      "1d83ad87ce3a452398858de191dc5aa4",
      "74feac17f82340b1be9a7a5d95501b5d",
      "b45727ee9f6f4354b777ca09cd10116f",
      "333e30a423954fde8ce55ea6eef6f307",
      "02fec8d46bf74a0aa1b05e9069114701",
      "8730f90e7e0848569fcc835ce23cb749",
      "9da8cd63053d427a8756995c37a76dc0",
      "b2f22516904b414a8833a91434706d0b",
      "2f510f41a02740dcb1adde55a7d5b483",
      "fc219b6f58d1460687f4d4da8cb83a94",
      "b89b8da1260c4b1086bc124fee2ea33b",
      "4e27821252854c8db12927d33df6316c",
      "34bfa962bc6c43c6b07af4d3d3407433",
      "fe50bee9d9ed4af681b4b00b8a0fc253",
      "8e73b7f03c1749098f437f85e19586fd",
      "d1946e6477ee46128876cea80e332666",
      "133497e3d6b9434abed4035beb0acf0e",
      "89d682616e9f4f189e26bc0b234158fa",
      "502b44e5b2b0466b9a64f2a111d00d8b",
      "1a4097be8bf448658c8b266c0b59f667",
      "f1a873a03abb469d845a019ffa9f6c3d",
      "df256ced714e42ffa7dfe5296c565436",
      "f26bbf77ced8464686d73420563834e6",
      "5aa850f3a72842498be0fa62449298d3",
      "7525e3f2119f4895860777c393ebadf4",
      "4fd23102543140ee836a844fad50dc6b",
      "06732d0ed63f42e7b6d5408579f015c6",
      "edf9d6fa6ca746f48bf01842dc014b7b",
      "79969490f2e24bb48ce41f28d801a129",
      "54f3d139fdf7412d8813578e4c54dc99",
      "2bca586cbea648288c2f335ae441e927",
      "3b52ce46795f4722ac0bb0d34c3e2ce8",
      "b233b8d6674e4945a35f99c67eb98597",
      "cd9596d9776d45faaa645664df93e653"
     ]
    },
    "executionInfo": {
     "elapsed": 15733,
     "status": "ok",
     "timestamp": 1752092340078,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "67KQKNT-ktnp",
    "outputId": "fe59c2cd-e6c8-42ad-f420-99772a206434"
   },
   "outputs": [],
   "source": [
    "# load BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "ffa343341371499e81e3f35fa55933f5",
      "6fc3b31725b44658bd56b78deea21082",
      "c839ee9011be4e9ca079cd9870992864",
      "097a1b0b2dca4b89ae2cbcea601b0bb3",
      "d470e508c7a642c68b93ce3a4e33a676",
      "a924068045744ec5b9b17d6115d8e5fd",
      "0874c286854440fc9a8f3bae63126796",
      "c17b29c536c44e8da78df26b5410946a",
      "54973bf8f1da4e9c914e47c2e31b114d",
      "a2b629c86ea146e09594f2580523eaf2",
      "e2b65140cf2645af8f911c15ece533cf"
     ]
    },
    "executionInfo": {
     "elapsed": 12375,
     "status": "ok",
     "timestamp": 1752092605807,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "-JnASjuSqVdb",
    "outputId": "9a2432d2-8972-4656-e883-65e7bd297207"
   },
   "outputs": [],
   "source": [
    "# Due to previous errors, I will replace NaN or non-string values with an empty string\n",
    "df_clean['combined_text'] = df_clean['combined_text'].fillna('').astype(str)\n",
    "# encode combined text\n",
    "bert_embeddings = model.encode(df_clean['combined_text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BK12QDqektra"
   },
   "outputs": [],
   "source": [
    "# movies numerical metadata\n",
    "#metadata = df_clean[['release_date', 'popularity']].fillna(0)\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler()\n",
    "normalized_metadata = scaler.fit_transform(metadata)\n",
    "\n",
    "# BERT + Metadata\n",
    "hybrid_features = np.hstack([bert_embeddings, normalized_metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sR6ahR1piCSw"
   },
   "outputs": [],
   "source": [
    "# computer similirity cosine\n",
    "similarity_matrix = cosine_similarity(hybrid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Azr5aJsi5s6"
   },
   "outputs": [],
   "source": [
    "# updated recommendation movies w/ similarity scores, genre and keywords\n",
    "def recommend_movies(title, top_n=10):\n",
    "    idx = df_clean[df_clean['title'].str.lower() == title.lower()].index\n",
    "    if len(idx) == 0:\n",
    "        print(\"Movie not found.\")\n",
    "        return\n",
    "\n",
    "    idx = idx[0]\n",
    "    sim_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    recommendations = df_clean[['title', 'release_year', 'genres', 'keywords', 'overview']].iloc[movie_indices].copy()\n",
    "    recommendations['similarity_score'] = [sim[1] for sim in sim_scores]\n",
    "\n",
    "    for _, row in recommendations.iterrows():\n",
    "        movie_title = row['title']\n",
    "        release_year = row['release_year']\n",
    "        print(f\"\\n {movie_title} ({release_year}) — Similarity Score: {row['similarity_score']:.3f}\")\n",
    "        print(f\"Genres: {row['genres']}\")\n",
    "        print(f\"Keywords: {row['keywords']}\")\n",
    "        poster_url = get_poster_url(movie_title)\n",
    "        if poster_url:\n",
    "            display(Image(url=poster_url))\n",
    "        else:\n",
    "            print(\"Poster not found.\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    return recommendations.sort_values(by='similarity_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQE5FfATefyb"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# API key\n",
    "api_key = \"b400409e22d456acb002b98fa90b2c2d\" # I got this key by registering on TMDB website\n",
    "\n",
    "# get poster URL from TMDb\n",
    "def get_poster_url(movie_title):\n",
    "    try:\n",
    "        url = f\"https://api.themoviedb.org/3/search/movie?api_key={api_key}&query={movie_title}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if data[\"results\"] and data[\"results\"][0].get(\"poster_path\"):\n",
    "            poster_path = data[\"results\"][0][\"poster_path\"]\n",
    "            return f\"https://image.tmdb.org/t/p/w300{poster_path}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching poster for {movie_title}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3754,
     "status": "ok",
     "timestamp": 1752092792382,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "gAQG5KXooRSY",
    "outputId": "53cbd225-6117-4804-885c-6def5aaf5312"
   },
   "outputs": [],
   "source": [
    "recommend_movies(\"Toy Story\", top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZaqImCuuzsJ"
   },
   "source": [
    "# K-meamns clustering for Bert recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ3O-k_roRV4"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBdLddJ6oRZV"
   },
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncbYVAv4oRcc"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(bert_embeddings)\n",
    "df['pca1'] = pca_result[:, 0]\n",
    "df['pca2'] = pca_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1752087673750,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "61MXZns4vCQS",
    "outputId": "22f99c0f-4169-45f7-a7ed-1f8c0c9c80f9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='cluster', palette='tab10', alpha=0.6)\n",
    "\n",
    "# Add labels for a few example movies (1 per cluster)\n",
    "sample_titles = df.groupby('cluster').apply(lambda x: x.sample(1, random_state=11)).reset_index(drop=True)\n",
    "for _, row in sample_titles.iterrows():\n",
    "    plt.text(row['pca1'], row['pca2'], row['title'], fontsize=9)\n",
    "\n",
    "plt.title(\"BERT-based Movie Clusters\")\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1752087679703,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "sAd7kCyKvCXr",
    "outputId": "6f247838-2f63-42c9-f7a5-62b2ecfe169d"
   },
   "outputs": [],
   "source": [
    "print(\"\\nTop representative movies per BERT-based cluster:\")\n",
    "for i in range(n_clusters):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "\n",
    "    # get indices of items in this cluster\n",
    "    cluster_indices = df[df['cluster'] == i].index\n",
    "\n",
    "    # get the centroid of the cluster\n",
    "    centroid = kmeans.cluster_centers_[i].reshape(1, -1)\n",
    "\n",
    "    # compute cosine similarity to the centroid\n",
    "    cluster_embeddings = bert_embeddings[cluster_indices]\n",
    "    sims = cosine_similarity(cluster_embeddings, centroid).flatten()\n",
    "\n",
    "    # get top 5 most representative movies\n",
    "    top_indices = cluster_indices[np.argsort(sims)[-5:][::-1]]\n",
    "    for idx in top_indices:\n",
    "        print(f\"  {df.loc[idx, 'title']} - {df.loc[idx, 'genres']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXyXXakptY33"
   },
   "source": [
    "# Unsupervised LSTM Model (recommendation system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMQhRV0WvCao"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MexbhUDvvCds"
   },
   "outputs": [],
   "source": [
    "# Load dataframe (df) from google drive running the top cells\n",
    "\n",
    "# clean and combine text features as with TF-IDF and BERT\n",
    "df_clean = df[['title', 'overview', 'genres', 'keywords', 'popularity', 'release_date']].dropna()\n",
    "\n",
    "# combine text fields into one\n",
    "df_clean['combined_text'] = df_clean['title'] + \" \" + df_clean['overview'] + \" \" + df_clean['genres'] + \" \" + df_clean['keywords']\n",
    "\n",
    "# normalize popularity and release date\n",
    "df_clean['release_date'] = pd.to_datetime(df_clean['release_date'], errors='coerce').dt.year.fillna(0).astype(int)\n",
    "scaler = MinMaxScaler()\n",
    "df_clean[['popularity', 'release_date']] = scaler.fit_transform(df_clean[['popularity', 'release_date']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1752169946859,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "q2JxcT_FvCgT",
    "outputId": "fc3d943c-034f-4345-c9c3-0b27707e395a"
   },
   "outputs": [],
   "source": [
    "# example of combined_text for reference purposes\n",
    "df_clean['combined_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1752169952840,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "UgBvGIdIvkam",
    "outputId": "bdc2b266-b948-43e3-adb3-ebe3c8bb2ca2"
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hsrqP0fvkeb"
   },
   "outputs": [],
   "source": [
    "# format JSON strings from genre and keyboards\n",
    "df_clean['genres'] = df_clean['genres'].apply(extract_names)\n",
    "df_clean['keywords'] = df_clean['keywords'].apply(extract_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1752170016416,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "1BSb3N0hvkil",
    "outputId": "9e3f14d3-9772-4d02-e194-30571fcea702"
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6S49iqdpj4Ts"
   },
   "outputs": [],
   "source": [
    "# text preprocessing and tokenization\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df_clean['combined_text'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df_clean['combined_text'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# metadata as additional input\n",
    "metadata_features = df_clean[['popularity', 'release_date']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1752171574267,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "YPh6oVUBj4Wx",
    "outputId": "def20ba4-54c0-4fd6-c3d2-e458f02c1e9f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "\n",
    "# inputs for the model\n",
    "text_input = Input(shape=(100,), name=\"text_input\")\n",
    "meta_input = Input(shape=(2,), name=\"meta_input\")\n",
    "\n",
    "# LSTM on text\n",
    "embedding = Embedding(input_dim=10000, output_dim=64, input_length=100)(text_input)\n",
    "lstm_out = LSTM(64)(embedding)\n",
    "\n",
    "# combine LSTM and metadata\n",
    "merged = Concatenate()([lstm_out, meta_input])\n",
    "dense = Dense(64, activation='relu')(merged)\n",
    "output = Dense(32, activation='relu')(dense)  # This becomes the embedding vector for recommendations\n",
    "\n",
    "# define model\n",
    "model = Model(inputs=[text_input, meta_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 858560,
     "status": "ok",
     "timestamp": 1752173170764,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "QJ3Hb13dj4aQ",
    "outputId": "f950267b-7e32-481b-9be1-5de634ef6a6f"
   },
   "outputs": [],
   "source": [
    "# dummy output to learn identity (FYI each movie vector is like a label)\n",
    "X_text = padded_sequences\n",
    "X_meta = metadata_features\n",
    "\n",
    "# random targets for training embeddings\n",
    "y = np.random.rand(len(df_clean), 32)\n",
    "\n",
    "# train the model\n",
    "model.fit([X_text, X_meta], y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1752173201478,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "Hjn-xTQKj4dS",
    "outputId": "8a51c5fa-701a-43d7-f9dd-f1ae9d887bd2"
   },
   "outputs": [],
   "source": [
    "# Get learned embeddings for all movies\n",
    "movie_embeddings = model.predict([X_text, X_meta])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_lstm(movie_title, top_n=5):\n",
    "    idx = df_clean[df_clean['title'].str.lower() == movie_title.lower()].index\n",
    "    if len(idx) == 0:\n",
    "        print(\"Movie not found.\")\n",
    "        return\n",
    "\n",
    "    idx = idx[0]\n",
    "    query_embedding = movie_embeddings[idx]\n",
    "    sim_scores = cosine_similarity([query_embedding], movie_embeddings)[0]\n",
    "    top_indices = np.argsort(sim_scores)[::-1][1:top_n+1]\n",
    "\n",
    "    recommendations = df_clean.iloc[top_indices][['title', 'genres', 'keywords', 'overview']].copy()\n",
    "    recommendations['similarity_score'] = sim_scores[top_indices]\n",
    "\n",
    "    return recommendations.sort_values(by='similarity_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1752173230515,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "FPevwDaAj4gE",
    "outputId": "5f511676-f584-41c4-c512-2bfd87ac6bdf"
   },
   "outputs": [],
   "source": [
    "recommend_lstm(\"Superman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSrqyAj216Vh"
   },
   "source": [
    "# GLOVE + LSTM Model w/ additional numeric features (Supervised training)\n",
    "\n",
    "## 1st load the df from the top df code / google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4SuDu1Nj4jP"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rl5ia29oj4mD"
   },
   "outputs": [],
   "source": [
    "# combine text fields\n",
    "df['combined_text'] = df['overview'].fillna('') + \" \" + \\\n",
    "                      df['genres'].fillna('') + \" \" + \\\n",
    "                      df['keywords'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksh_0np82n1C"
   },
   "outputs": [],
   "source": [
    "# function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "#apply to the combined text\n",
    "df['combined_text'] = df['combined_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0bfnd2E2n4K"
   },
   "outputs": [],
   "source": [
    "#  text tokenize\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['combined_text'])\n",
    "sequences = tokenizer.texts_to_sequences(df['combined_text'])\n",
    "X_text = pad_sequences(sequences, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZDBihQ72n7R"
   },
   "outputs": [],
   "source": [
    "# normalizing all nmerical features\n",
    "df['release_year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year.fillna(0).astype(int)\n",
    "df[['popularity', 'vote_average', 'vote_count', 'runtime']] = df[['popularity', 'vote_average', 'vote_count', 'runtime']].fillna(0)\n",
    "numerical = df[['release_year', 'popularity', 'vote_average', 'vote_count', 'runtime']]\n",
    "scaler = MinMaxScaler()\n",
    "X_num = scaler.fit_transform(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kezu8qqd2n9_"
   },
   "outputs": [],
   "source": [
    "# language encoding\n",
    "df['original_language'] = df['original_language'].fillna('unknown')\n",
    "le = LabelEncoder()\n",
    "X_lang = le.fit_transform(df['original_language']).reshape(-1, 1)\n",
    "\n",
    "# numerical + language\n",
    "X_meta = np.hstack((X_num, X_lang))\n",
    "\n",
    "# input for LSTM\n",
    "X_final = [X_text, X_meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1752366394926,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "E8NVSFKZ2oAv",
    "outputId": "30be2680-dd46-472a-f3f0-2cc5527eec16"
   },
   "outputs": [],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkGUedO62oD-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# similarity scores based on vote average\n",
    "vote_scores = df['vote_average'].values.reshape(-1, 1)\n",
    "y_similarity = cosine_similarity(vote_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 185174,
     "status": "ok",
     "timestamp": 1752366592172,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "c1a61603",
    "outputId": "7607d113-5c41-4135-a9b0-58d0f678924d"
   },
   "outputs": [],
   "source": [
    "# download GloVe embeddings\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLMa2KYCj4pE"
   },
   "outputs": [],
   "source": [
    "# Glove embedding\n",
    "embedding_index = {}\n",
    "with open('/content/glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "embedding_dim = 100\n",
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = np.zeros((10000, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= 10000:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "executionInfo": {
     "elapsed": 3450,
     "status": "ok",
     "timestamp": 1752366675630,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "UTjNtFqwj4sb",
    "outputId": "5e14a7f9-62ab-4930-a3c7-49b27ac51852"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Dropout\n",
    "\n",
    "# text input\n",
    "text_input = Input(shape=(300,))\n",
    "embed = Embedding(input_dim=10000, output_dim=100, weights=[embedding_matrix], input_length=300, trainable=False)(text_input)\n",
    "lstm_out = LSTM(64)(embed)\n",
    "\n",
    "# metadata input\n",
    "meta_input = Input(shape=(X_meta.shape[1],))\n",
    "meta_dense = Dense(32, activation='relu')(meta_input)\n",
    "\n",
    "# combine\n",
    "combined = Concatenate()([lstm_out, meta_dense])\n",
    "combined = Dropout(0.3)(combined)\n",
    "output = Dense(1, activation='sigmoid')(combined)\n",
    "\n",
    "model = Model(inputs=[text_input, meta_input], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134475,
     "status": "ok",
     "timestamp": 1752366841073,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "De4ZeGOa4e0w",
    "outputId": "62525d48-d58c-49a3-8dc7-09c2cd97ffce"
   },
   "outputs": [],
   "source": [
    "# sample dummy labels (1 if vote_average diff < 0.5 else 0)\n",
    "labels = np.where(abs(df['vote_average'].values - df['vote_average'].values.mean()) < 0.5, 1, 0)\n",
    "\n",
    "model.fit(X_final, labels, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1752366948304,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "ZxY7Q39k4e39",
    "outputId": "a08e8e16-fec1-4e70-e6e6-151207c7abea"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# xtract features from the penultimate layer\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.get_layer(index=-2).output)\n",
    "\n",
    "# feature embeddings for all movies\n",
    "movie_embeddings = feature_extractor.predict(X_final, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqOwfTMc4e7T"
   },
   "outputs": [],
   "source": [
    "# compute pairwise cosine similarity between all movies\n",
    "similarity_matrix = cosine_similarity(movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwVsrFAX4e-J"
   },
   "outputs": [],
   "source": [
    "def recommend_movies_lstm(title, top_n=5):\n",
    "    # find movie index\n",
    "    idx = df[df['title'].str.lower() == title.lower()].index\n",
    "    if len(idx) == 0:\n",
    "        print(\"Movie not found.\")\n",
    "        return\n",
    "    idx = idx[0]\n",
    "\n",
    "    # Get similarity scores for the movie\n",
    "    sim_scores = list(enumerate(similarity_matrix[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Skip the movie itself (first match) and select top-N\n",
    "    sim_scores = sim_scores[1:top_n + 1]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    print(f\"\\nTop {top_n} similar movies to: {df.iloc[idx]['title']}\")\n",
    "    for i in movie_indices:\n",
    "        title = df.iloc[i]['title']\n",
    "        score = sim_scores[movie_indices.index(i)][1]\n",
    "        print(f\"{title} — Similarity Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1752368316387,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "-fLxOEYn4fB0",
    "outputId": "2d7806d8-03c6-4e8c-c665-073f3ab0b8d7"
   },
   "outputs": [],
   "source": [
    "recommend_movies_lstm(\"Transformers\", top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MPVq3EjMiBq"
   },
   "outputs": [],
   "source": [
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# cluster into 5 groups\n",
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1752367207089,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "ZcttFbl7MiFh",
    "outputId": "c7439bc0-20d9-47d7-f26d-147a1e6c4bd5"
   },
   "outputs": [],
   "source": [
    "# 5 movies per cluster for inspection\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    sample_movies = df[df['cluster'] == i].sample(5, random_state=42)\n",
    "    for title in sample_movies['title']:\n",
    "        print(f\"  - {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1752367630226,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "S713gt6kMiL5",
    "outputId": "2c84f15b-a7c4-49ae-e121-02cac5d70198"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nTop representative movies per LSTM-based cluster:\")\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "\n",
    "    # Get indices of items in this cluster\n",
    "    cluster_indices = df[df['cluster'] == i].index\n",
    "\n",
    "    # Get the centroid of the cluster\n",
    "    centroid = kmeans.cluster_centers_[i].reshape(1, -1)\n",
    "\n",
    "    # Compute cosine similarity to the centroid\n",
    "    cluster_embeddings = movie_embeddings[cluster_indices]\n",
    "    sims = cosine_similarity(cluster_embeddings, centroid).flatten()\n",
    "\n",
    "    # Get top 5 most representative movies\n",
    "    top_indices = cluster_indices[np.argsort(sims)[-5:][::-1]]\n",
    "    for idx in top_indices:\n",
    "        print(f\"  {df.loc[idx, 'title']} - {df.loc[idx, 'genres']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "executionInfo": {
     "elapsed": 4471,
     "status": "ok",
     "timestamp": 1752367826206,
     "user": {
      "displayName": "Rene Ortiz",
      "userId": "03736842153688856058"
     },
     "user_tz": 420
    },
    "id": "1XwfxDFzMiPE",
    "outputId": "79486807-5efb-4c29-eff0-a5bb6f073a4c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "# Reduce to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(movie_embeddings)\n",
    "\n",
    "# Add PCA components to the DataFrame\n",
    "df['pca1'] = reduced_embeddings[:, 0]\n",
    "df['pca2'] = reduced_embeddings[:, 1]\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "palette = sns.color_palette(\"hsv\", len(df['cluster'].unique()))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='cluster', palette=palette, alpha=0.7)\n",
    "\n",
    "# Optional: Add movie titles for a few representative samples per cluster\n",
    "sample_titles = df.groupby('cluster').apply(lambda x: x.sample(1, random_state=42))\n",
    "for _, row in sample_titles.iterrows():\n",
    "    plt.text(row['pca1'], row['pca2'], row['title'], fontsize=8)\n",
    "\n",
    "plt.title(\"LSTM-based Movie Clusters (PCA Projection)\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwwbKyK2Sxx2"
   },
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8HJwYftT3Cn"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhrV9rt4T3LN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68ERuItpT3Po"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6DElt0NT3cQ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNhugAYxd8nIcSeWduUgKH9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
